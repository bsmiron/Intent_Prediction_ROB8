{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bsmiron/Intent_Prediction_ROB8/blob/main/hand_kf_tracking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "777NokIvzNO1"
      },
      "outputs": [],
      "source": [
        "!pip3 install MediaPipe\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_UDhOIZny6qU"
      },
      "outputs": [],
      "source": [
        "from numpy.core.arrayprint import array2string\n",
        "from pickle import TRUE\n",
        "import numpy as np\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "import math\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "F = 640\n",
        "Sx = 1\n",
        "Sy = 1\n",
        "FX = -F/Sx\n",
        "FY = -F/Sy\n",
        "PPX = 320\n",
        "PPY = 240\n",
        "CamMatrix = np.asarray([[FX, 0.0, PPX, 0],\n",
        "                        [0.0, FY, PPY, 0],\n",
        "                        [0.0, 0.0, 1.0, 0]])\n",
        "\n",
        "\n",
        "# Initialize KF from OpenCV\n",
        "\n",
        "class KalmanFilter2D:\n",
        "    kf = cv2.KalmanFilter(4, 2)\n",
        "    kf.measurementMatrix = np.array([[1, 0, 0, 0],\n",
        "                                     [0, 1, 0, 0]], np.float32)\n",
        "\n",
        "    kf.transitionMatrix = np.array([[1, 0, 1, 0],\n",
        "                                    [0, 1, 0, 1],\n",
        "                                    [0, 0, 1, 0],\n",
        "                                    [0, 0, 0, 1]], np.float32)\n",
        "\n",
        "    def estimamte_2d(self, pixel_x, pixel_y):\n",
        "        measured = np.array([[np.float32(pixel_x)], [np.float32(pixel_y)]])\n",
        "        self.kf.correct(measured)\n",
        "        predicted = self.kf.predict()\n",
        "        int_predicted = predicted.astype(int)\n",
        "        return int_predicted[0], int_predicted[1]\n",
        "\n",
        "\n",
        "class KalmanFilter3D:\n",
        "    def __init__(self, deltaT=1):\n",
        "        self.kf = cv2.KalmanFilter(6, 3)\n",
        "        self.deltaT = deltaT\n",
        "\n",
        "        self.kf.measurementMatrix = np.array([[1, 0, 0, 0, 0, 0],\n",
        "                                              [0, 1, 0, 0, 0, 0],\n",
        "                                              [0, 0, 1, 0, 0, 0]], np.float32)\n",
        "        self.kf.transitionMatrix = self.constructTransitionMatrix()\n",
        "\n",
        "    def constructTransitionMatrix(self):\n",
        "        return np.array([[1, 0, 0, self.deltaT, 0, 0],\n",
        "                         [0, 1, 0, 0, self.deltaT, 0],\n",
        "                         [0, 0, 1, 0, 0, self.deltaT],\n",
        "                         [0, 0, 0, 1, 0, 0],\n",
        "                         [0, 0, 0, 0, 1, 0],\n",
        "                         [0, 0, 0, 0, 0, 1]], np.float32)\n",
        "\n",
        "    def estimate_3d(self, camera_frame_x, camera_frame_y, camera_frame_z):\n",
        "        measured = np.asanyarray([camera_frame_x, camera_frame_y, camera_frame_z]).astype(\"float32\")\n",
        "        self.kf.correct(measured)\n",
        "        predicted = self.kf.predict().astype(\"int16\")\n",
        "        return predicted[0][0], predicted[1][0], predicted[2][0]\n",
        "\n",
        "\n",
        "def get_coordinate(POI, depth_image, matrix=CamMatrix, shittyRecording=False):\n",
        "    if shittyRecording:\n",
        "        Z = depth_image[POI[1], POI[0]] * 40\n",
        "    else:\n",
        "        Z = depth_image[POI[1], POI[0]]\n",
        "    u = POI[0] * Z\n",
        "    v = POI[1] * Z\n",
        "    X = (u - matrix[0, 2] * Z) / (matrix[0, 0])\n",
        "    Y = (v - matrix[1, 2] * Z) / (matrix[1, 1])\n",
        "    return [int(X), int(Y), int(Z)]\n",
        "\n",
        "def get_pixels (xyz):\n",
        "   pixel_u = 0\n",
        "   pixel_v = 0\n",
        "   uvw = np.matmul(CamMatrix, xyz)\n",
        "   # print(uvw)\n",
        "   # print(\"uvw: \", uvw)\n",
        "   if uvw[2] != 0:\n",
        "    # pixel_u = color_image.shape[1] - uvw[0]/uvw[2]\n",
        "    # pixel_v = color_image.shape[0] - uvw[1]/uvw[2]\n",
        "    pixel_u = uvw[0]/uvw[2]\n",
        "    pixel_v = uvw[1]/uvw[2]\n",
        "   \n",
        "   return int(pixel_u), int(pixel_v)\n",
        "  \n",
        "\n",
        "# Check if the path is correct\n",
        "rgb_cap = cv2.VideoCapture('/content/drive/MyDrive/ROB8/Project/depth_videos_for_bogdan/color_video_of_hand.avi')\n",
        "depth_cap = cv2.VideoCapture('/content/drive/MyDrive/ROB8/Project/depth_videos_for_bogdan/depth_video_of_hand.avi')\n",
        "\n",
        "# Check if I'm capturing\n",
        "if not rgb_cap.isOpened() or not depth_cap.isOpened():\n",
        "    print('Problem with captureing frames, procede further investigations')\n",
        "\n",
        "# MediaPipe Magic\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_drawing_styles = mp.solutions.drawing_styles\n",
        "mp_hands = mp.solutions.hands\n",
        "\n",
        "kfobj2d = KalmanFilter2D()\n",
        "kfobj3d = KalmanFilter3D()\n",
        "kfupdate3D = KalmanFilter3D()\n",
        "kfuupdate3D = KalmanFilter3D()\n",
        "\n",
        "measured_points = []\n",
        "predicted_points = []\n",
        "predicted_points_update1 = []\n",
        "predicted_points_update2 = []\n",
        "velocities = []\n",
        "x_line = []\n",
        "y_line = []\n",
        "z_line = []\n",
        "\n",
        "frame = 0\n",
        "\n",
        "d2_measured = []\n",
        "d2_predicted = []\n",
        "d2_predicted1 = []\n",
        "d2_predicted2 = []\n",
        "\n",
        "with mp_hands.Hands(\n",
        "        model_complexity=0,\n",
        "        min_detection_confidence=0.5,\n",
        "        min_tracking_confidence=0.5) as hands:\n",
        "    while rgb_cap.isOpened() and depth_cap.isOpened():\n",
        "        # print(rgb_cap.isOpened(), depth_cap.isOpened())\n",
        "        success, color_image = rgb_cap.read()\n",
        "        _, depth_image = depth_cap.read()\n",
        "        if depth_image is None or color_image is None:\n",
        "            break\n",
        "        depth_image_gray = cv2.cvtColor(depth_image, cv2.COLOR_RGB2GRAY)\n",
        "        if not success or not _:\n",
        "            print(\"Ignoring empty camera frame.\")\n",
        "            # If loading a video, use 'break' instead of 'continue'.\n",
        "            break\n",
        "\n",
        "        # To improve performance, optionally mark the image as not writeable to\n",
        "        # pass by reference.\n",
        "        color_image.flags.writeable = False\n",
        "        color_image = cv2.cvtColor(color_image, cv2.COLOR_BGR2RGB)\n",
        "        results = hands.process(color_image)\n",
        "\n",
        "        # Draw the hand annotations on the image.\n",
        "        color_image.flags.writeable = True\n",
        "        color_image = cv2.cvtColor(color_image, cv2.COLOR_RGB2BGR)\n",
        "        if results.multi_hand_landmarks:\n",
        "            for hand_landmarks in results.multi_hand_landmarks:\n",
        "\n",
        "                # mp_drawing.draw_landmarks(\n",
        "                # color_image,\n",
        "                # hand_landmarks,\n",
        "                # mp_hands.HAND_CONNECTIONS,\n",
        "                # mp_drawing_styles.get_default_hand_landmarks_style(),\n",
        "                # mp_drawing_styles.get_default_hand_connections_style())\n",
        "\n",
        "                for id, lm in enumerate(hand_landmarks.landmark):\n",
        "                    # print(id,lm) id = type of landmark; lm coordinates of the landmark\n",
        "                    h, w, c = color_image.shape\n",
        "                    cx, cy = int(lm.x * w), int(lm.y * h)\n",
        "\n",
        "                    if id == 9:  # and (cx - 20) < color_image.shape[0] and cx > 20 and (cy - 20) < color_image.shape[1] and cy > 20 :\n",
        "                        # print(cx, cy)\n",
        "                        update = 0\n",
        "                        cv2.circle(color_image, (cx, cy), 2, (255, 0, 255), 2)\n",
        "                        # print([cx, cy])\n",
        "                        d2_measured.append([cx, cy])\n",
        "                        hand_x, hand_y, hand_z = get_coordinate([cx, cy], depth_image_gray, shittyRecording=True)\n",
        "                        measured_points.append([hand_x, hand_y, hand_z])\n",
        "                        # print(\"Hand: \", hand_x, hand_y, hand_z)\n",
        "\n",
        "                        # 3D KF\n",
        "                        pred3_x, pred3_y, pred3_z = kfobj3d.estimate_3d(hand_x, hand_y, hand_z)\n",
        "                        # convert real world coordinates in pixels to show the dot in image\n",
        "                        XYZ1_pred = np.asanyarray([pred3_x, pred3_y, pred3_z, 1])\n",
        "                        predicted_points.append(XYZ1_pred[:-1])\n",
        "                        \n",
        "                        # Future update estimation\n",
        "                        if update == 0:\n",
        "                          # print(pred3_x, pred3_y, pred3_z)\n",
        "\n",
        "                          pred3_1_x, pred3_1_y, pred3_1_z = kfupdate3D.estimate_3d(pred3_x, pred3_y, pred3_z)\n",
        "                          XYZ1_1_pred = np.asanyarray([pred3_1_x, pred3_1_y, pred3_1_z, 1])\n",
        "                          predicted_points_update1.append(XYZ1_1_pred[:-1])\n",
        "                          up_x, up_y = get_pixels(XYZ1_1_pred)\n",
        "                          cv2.circle(color_image, (int(up_x), int(up_y)), 2, (255, 60, 0), 2)\n",
        "                          d2_predicted1.append([up_x, up_y])\n",
        "                          update = 1\n",
        "\n",
        "                          if update == 1:\n",
        "                          \n",
        "                            pred3_2_x, pred3_2_y, pred3_2_z = kfuupdate3D.estimate_3d(pred3_1_x, pred3_1_y, pred3_1_z)\n",
        "                            XYZ1_2_pred = np.asanyarray([pred3_2_x, pred3_2_y, pred3_2_z, 1])\n",
        "                            predicted_points_update2.append(XYZ1_2_pred[:-1])\n",
        "                            up_x_2, up_y_2 = get_pixels(XYZ1_2_pred)\n",
        "                            cv2.circle(color_image, (int(up_x_2), int(up_y_2)), 2, (255, 120, 120), 2)\n",
        "                            d2_predicted2.append([up_x_2, up_y_2])\n",
        "                            update = 2\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                        # print(XYZ1_pred)\n",
        "                        uvw = np.matmul(CamMatrix, XYZ1_pred)\n",
        "                        # print(uvw)\n",
        "                        # print(\"uvw: \", uvw)\n",
        "                        if uvw[2] != 0:\n",
        "                            # pixel_u = color_image.shape[1] - uvw[0]/uvw[2]\n",
        "                            # pixel_v = color_image.shape[0] - uvw[1]/uvw[2]\n",
        "                            pixel_u = uvw[0]/uvw[2]\n",
        "                            pixel_v = uvw[1]/uvw[2]\n",
        "                            cv2.circle(color_image, (int(pixel_u), int(pixel_v)), 2, (255, 255, 0), 2)\n",
        "                            d2_predicted.append([int(pixel_u), int(pixel_v)])\n",
        "\n",
        "        print(frame)\n",
        "\n",
        "        cv2_imshow(color_image)\n",
        "        frame += 1\n",
        "        # cv2.imwrite(\"test.jpg\", color_image)\n",
        "        if cv2.waitKey(5) & 0xFF == 27:\n",
        "            break\n",
        "\n",
        "# figg = plt.figure()\n",
        "# axx = plt.axes()\n",
        "\n",
        "# d2_measured = np.asanyarray(d2_measured)[10:]\n",
        "# d2_predicted = np.asanyarray(d2_predicted)[10:]\n",
        "# d2_predicted1 = np.asanyarray(d2_predicted1)[10:]\n",
        "# d2_predicted2 = np.asanyarray(d2_predicted2)[10:]\n",
        "\n",
        "# axx.scatter(d2_measured[40][0], d2_measured[40][1], 'pink')\n",
        "# axx.scatter(d2_predicted[40][0], d2_predicted[40][1], 'green')\n",
        "# axx.scatter(d2_predicted1[40][0], d2_predicted1[40][1], 'blue')\n",
        "# axx.scatter(d2_predicted2[40][0], d2_predicted2[40][1], 'orange')\n",
        "\n",
        "# axx.set_xlabel('x')\n",
        "# axx.set_ylabel('y')\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = plt.axes(projection='3d')\n",
        "# ax = fig.ax_subplot(projection='3d')\n",
        "\n",
        "array_measured = np.asanyarray(measured_points)[10:]\n",
        "array_predicted = np.asanyarray(predicted_points)[10:]\n",
        "array_predicted_update1 = np.asanyarray(predicted_points_update1)[10:]\n",
        "array_predicted_update2 = np.asanyarray(predicted_points_update2)[10:]\n",
        "\n",
        "# print(array_measured[140][0], array_measured[140][1], array_measured[140][2])\n",
        "#one frame\n",
        "\n",
        "ax.scatter3D(array_measured[140, 0], array_measured[140, 1], array_measured[140, 2], 'pink')\n",
        "ax.scatter3D(array_predicted[140, 0], array_predicted[140, 1], array_predicted[140, 2], 'turquoise')\n",
        "ax.scatter3D(array_predicted_update1[140, 0], array_predicted_update1[140, 1], array_predicted_update1[140, 2], 'blue')\n",
        "ax.scatter3D(array_predicted_update2[140, 0], array_predicted_update2[140, 1], array_predicted_update2[140, 2], 'orange')\n",
        "\n",
        "\n",
        "\n",
        "# ax.plot3D(array_measured[:, 0], array_measured[:, 1], array_measured[:, 2], 'pink')\n",
        "# ax.plot3D(array_predicted[:, 0], array_predicted[:, 1], array_predicted[:, 2], 'turquoise')\n",
        "# ax.plot3D(array_predicted_update1[:, 0], array_predicted_update1[:, 1], array_predicted_update1[:, 2], 'blue')\n",
        "# ax.plot3D(array_predicted[:, 0], array_predicted[:, 1], array_predicted[:, 2], 'orange')\n",
        "# ax.scatter([array_measured[:, 0], array_predicted[:, 0]],[array_measured[:, 1], array_predicted[:, 1]], [array_measured[:, 2], array_predicted[:, 2]], c = \"red\", s=1)\n",
        "\n",
        "line_x = np.stack((array_measured[:, 0], array_predicted[:, 0]), axis = -1)\n",
        "# print(line_x)\n",
        "line_y = np.stack((array_measured[:, 1], array_predicted[:, 1]), axis = -1)\n",
        "# print(line_y)\n",
        "line_z = np.stack((array_measured[:, 2], array_predicted[:, 2]), axis = -1)\n",
        "# print(line_z)\n",
        "\n",
        "# for x_measured, x_predicted in array_measured[:, 0], array_predicted[:,0]:\n",
        "#     x_line = [x_measured, x_predicted]\n",
        "#     print(x_line)\n",
        "   \n",
        "\n",
        "# ax.plot3D(line_x, line_y, line_z, color = \"black\")\n",
        "\n",
        "\n",
        "ax.set_xlabel(\"x\")\n",
        "ax.set_ylabel(\"y\")\n",
        "ax.set_zlabel(\"z\")\n",
        "plt.show()\n",
        "rgb_cap.release()\n",
        "depth_cap.release()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "hand_kf_tracking.ipynb",
      "provenance": [],
      "mount_file_id": "1Xbj_6fcNzAGptYJfa7gflf3s_nBVL9Qh",
      "authorship_tag": "ABX9TyOBRYX9+BbRwEBaPARDi9Ie",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}